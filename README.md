# Real-Time-Sign-Language-Recognition
This project implements an LSTM-based model for recognizing sign language gestures, specifically targeting actions like 'hello', 'thanks', 'nothing', and 'I love you'. Using PyTorch, it processes sequences of hand gestures, trains the model, and evaluates performance through confusion matrices and probabilities.
